---
aliases: 
date: 2024-10-24
author: Jerry Hsiung
draft: true
URL:
---
ì´ê±° [[ğŸ“¦ï¸BASALT]]ì˜ contributionê³¼ ìƒë‹¹íˆ ìœ ì‚¬í•˜ë‹¤.  mappingì— ê´€ë ¨í•´ì„œ ê·¸ëƒ¥ sparsityë¥¼ ì‚¬ìš©í•œ ë“¯. 
Marginalizationì„ í•˜ê²Œ ë˜ë©´, prior termì´ êµ‰ì¥íˆ denseí•´ì§€ëŠ” ê²ƒì„ ì•Œê³ ìˆì.
## Critique
- ì–»ì–´ê°ˆ ê²ƒ
- ì´ ë°©ë²•ì˜ ì¥ì  / ë¶€ì¡±í•œ ì 
- ì–´ë–»ê²Œ ì¨ë¨¹ì„ ìˆ˜ ìˆì„ì§€

## Introduction

- SLAMì—ì„œ íš¨ìœ¨ì ì¸ ê³„ì‚°ì„ ìœ„í•´ Sparsityê°€ ì¤‘ìš”í•˜ë‹¤.
- Marginalizationì€ linear prior term matrixë¥¼ denseí•˜ê²Œ ë§Œë“¤ê³ , ì´ê±°ëŠ” accuracyì™€ efficiencyë¥¼ ë–¨ì–´ëœ¨ë¦°ë‹¤.
- ë”°ë¼ì„œ sparsityë¥¼ ê°€ì§ê³¼ ë™ì‹œì— ì›ë˜ì˜ íŠ¹ì„±ì„ ê°€ì§€ê³  ìˆëŠ” matrixë¡œ recoveryì‹œí‚¤ì.

## Methodology
Marginalization ì „ëµì€ VINSì™€ ë¹„ìŠ·í•¨.

KL Divergenceë¥¼ ì´ìš©í•´ì„œ ì›ë˜ì˜ denseí•œ priorë¥¼ ê·¼ì‚¬í•¨. nonlinear factorë“¤ì„ ì´ìš©í•´ì„œ.


### IV - B. Information Sparsification
$$
\Lambda_{(\mathrm{MB)}} = \begin{bmatrix} \Lambda_{{\chi_{R}}{\chi_{R}}} \qquad \Lambda_{{\chi_{M}}{\chi_{R}}} \\ \Lambda_{{\chi_{R}}{\chi_{M}}} \qquad  \Lambda_{{\chi_{M}}{\chi_{M}}}   \end{bmatrix} 
$$

$\Lambda_t = \Lambda_{{\chi_R}{\chi_R}}- \Lambda_{{\chi_R}{\chi_M}} {\Lambda_{{\chi_M}{\chi_M}}}^{-1} \Lambda_{{\chi_M}{\chi_R}}$

$\chi_w = {K_w, F_w, L_w}$ 

dense prior information $\Lambda_t$ì€ ë‹¤ìŒê³¼ ê°™ì´ multivariate Gaussianì„ ë”°ë¦„ $p(\chi_t) \sim \mathcal{N}(\mu_t, \Lambda_t)$
1. NFR ë…¼ë¬¸ì²˜ëŸ¼ ì²˜ìŒì— Markov blanketì— ëŒ€í•´ factor graph topologyë¥¼ ë§Œë“¤ê±´ë° ì•„ë˜ì²˜ëŸ¼ $p_s(\chi_t)$ë¥¼ $p(\chi_t)$ì™€ (ì›ë˜ ê²ƒê³¼) ìœ ì‚¬í•´ì§€ê²Œ ë§Œë“œëŠ” ê±°ì„ ($\Sigma_t = \Lambda_t^{-1}$)
![[Pasted image 20241024203318.png]]  


$\Lambda_s = H_s^{\top}\Lambda_r H_s$


### IV-C. Topology Measurement Covariances Recovery
![[Pasted image 20241024210123.png]]
ì´ê²Œ ìœ„ì˜ ì‹ì´ë‘ ë˜‘ê°™ì€ë° squared error termí•˜ê³  dê°€ ë¹ ì ¸ìˆìŒ. ì–´ë–»ê²Œ ì†Œê±°ë¥¼ í•œ ê±¸ê¹Œ? 
#ì ê²€ 

ë³¸ ë…¼ë¬¸ì˜ measurement model ì€ í•­ìƒ full-rankí•˜ê³  invertibleí•œ Jacobian $H_s$ë¥¼ ì œê³µí•˜ê³  ìˆê¸° ë•Œë¬¸ì— 15ë²ˆ ì‹ì„ closed formìœ¼ë¡œ í’€ ìˆ˜ê°€ ìˆë‹¤.
$$
\Lambda_r^{(i)} = ( \big\{ H_s \Sigma_t H_s^{\top} \big\}^{(i) } )^{-1}
$$
(i)ëŠ” ië²ˆì§¸ matrix blockì„ ì˜ë¯¸í•¨.

ì•„ë˜ì˜ IJRR ë…¼ë¬¸ì— ìœ ë„ê³¼ì •ì´ ë‚˜ì™€ìˆë‹¤ê³  í•¨.

## Experiments
- Open dataset (EuRoC)ìœ¼ë¡œ í…ŒìŠ¤íŠ¸ ì§„í–‰í–ˆê³ , 
- ì—°ì‚°ëŸ‰ì´ ë§ì´ ê±¸ë¦°ë‹¤ëŠ” ë‹¨ì ì´ ìˆë‹¤. â†’ parallelizationìœ¼ë¡œ ê·¹ë³µ  ê°€ëŠ¥
	- ì£¼ë¡œ KLD optimizationì—ì„œ ì†Œìš”.
- ë‹¤ë¥¸ ì•Œê³ ë¦¬ì¦˜ë³´ë‹¤ ì„±ëŠ¥ì´ ë‚®ì€ ê±°ëŠ” blurred imageì´ê±°ë‚˜ dynamic lighting change ë•Œë¬¸ì„.

## â“ï¸Questions

### Future Articles to Read
Nonlinear factor recovery for long-term SLAM (IJRR)

## Link
[[ğŸ“¦ï¸BASALT]]
[[ğŸ“¦ï¸VINS-Fusion Review]]